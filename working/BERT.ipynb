{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goya5858/commonlitreadabilityprize/blob/main/working/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO8Aj3H68nPa"
      },
      "source": [
        "# Install libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpXmMzbt_oWU",
        "outputId": "1a6ee2f6-49e9-4b37-d592-ce3c7f26622e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC5H84YW7Oj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50025ea9-9a87-49d2-b86c-904ec1c7a2cc"
      },
      "source": [
        "compe_name = 'commonlitreadabilityprize'\n",
        "%cd /content/drive/MyDrive/kaggle/works/$compe_name/working/\n",
        "\n",
        "!pip install -q -q -q -U albumentations\n",
        "!pip install -q -q -q -U torch\n",
        "!pip install -q -q -q timm\n",
        "!pip install -q -q -q pytorch_lightning\n",
        "!pip install -q -q -q -U transformers\n",
        "!pip install -q -q -q -U sentencepiece\n",
        "\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "import warnings\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import cv2\n",
        "import PIL.Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "import timm\n",
        "\n",
        "import nltk\n",
        "from wordcloud import WordCloud\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop=stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from textblob import TextBlob,Word\n",
        "from collections import Counter\n",
        "import string\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection\n",
        "\n",
        "import transformers\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "\n",
        "from transformers import *\n",
        "\n",
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    #tf.random.set_seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/kaggle/works/commonlitreadabilityprize/working\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W3SxA_QKVvX"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E36RCH0tqF2H"
      },
      "source": [
        "DEVICE = 'cuda:0'\n",
        "\n",
        "#get_tokenizer = RobertaTokenizer\n",
        "#get_model     = BartForSequenceClassification\n",
        "get_tokenizer = AutoTokenizer #RobertaTokenizer より汎用性ある気がする　使い勝手的な面で\n",
        "get_model     = AutoModel\n",
        "\n",
        "#VOCAB_PATH = 'roberta-base'\n",
        "#MODEL_PATH = 'facebook/bart-large-mnli'\n",
        "VOCAB_PATH = 'bert-base-uncased'\n",
        "MODEL_PATH = 'bert-base-uncased'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n9rpp-77hDn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "da5be9b4-9e75-48bd-ef5d-49d27695cd0b"
      },
      "source": [
        "ROOT = f\"../input/{compe_name}/\"\n",
        "\n",
        "df = pd.read_csv(ROOT+'train.csv')\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>target</th>\n",
              "      <th>standard_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c12129c31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When the young people returned to the ballroom...</td>\n",
              "      <td>-0.340259</td>\n",
              "      <td>0.464009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85aa80a4c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
              "      <td>-0.315372</td>\n",
              "      <td>0.480805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b69ac6792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>As Roger had predicted, the snow departed as q...</td>\n",
              "      <td>-0.580118</td>\n",
              "      <td>0.476676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dd1000b26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>And outside before the palace a great garden w...</td>\n",
              "      <td>-1.054013</td>\n",
              "      <td>0.450007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37c1b32fb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Once upon a time there were Three Bears who li...</td>\n",
              "      <td>0.247197</td>\n",
              "      <td>0.510845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id url_legal  ...    target standard_error\n",
              "0  c12129c31       NaN  ... -0.340259       0.464009\n",
              "1  85aa80a4c       NaN  ... -0.315372       0.480805\n",
              "2  b69ac6792       NaN  ... -0.580118       0.476676\n",
              "3  dd1000b26       NaN  ... -1.054013       0.450007\n",
              "4  37c1b32fb       NaN  ...  0.247197       0.510845\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3lijAHPgNmyi",
        "outputId": "a535f6bf-5b51-4ef8-cda9-78f381280e9b"
      },
      "source": [
        "test_df = pd.read_csv(ROOT+'test.csv')\n",
        "test_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c0f722661</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f0953f0a5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0df072751</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It was a bright and cheerful scene that greete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>04caf4e0c</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Cell_division</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>Cell division is the process by which a parent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0e63f8bea</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Debugging</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>Debugging is the process of finding and resolv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            excerpt\n",
              "0  c0f722661  ...  My hope lay in Jack's promise that he would ke...\n",
              "1  f0953f0a5  ...  Dotty continued to go to Mrs. Gray's every nig...\n",
              "2  0df072751  ...  It was a bright and cheerful scene that greete...\n",
              "3  04caf4e0c  ...  Cell division is the process by which a parent...\n",
              "4  0e63f8bea  ...  Debugging is the process of finding and resolv...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfVQi9GWNxfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0f2c4b-7010-4d5d-bbdc-7890f583c86d"
      },
      "source": [
        "def prep_text(text_df):\n",
        "  text_df = text_df.str.replace(\"\\n\",\"\",regex=False)\n",
        "  return text_df.str.replace(\"\\'s\",r\"s\",regex=True).values\n",
        "\n",
        "df['excerpt']      = prep_text(df['excerpt'])\n",
        "test_df['excerpt'] = prep_text(test_df['excerpt'])\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = df['excerpt'].apply(lambda x: len(x.split())).max()\n",
        "\n",
        "tokenizer = get_tokenizer.from_pretrained(VOCAB_PATH,\n",
        "                                          model_max_length=MAX_SEQUENCE_LENGTH\n",
        "                                          )\n",
        "df['token']        = df['excerpt'].apply(tokenizer)\n",
        "test_df['token']   = test_df['excerpt'].apply(tokenizer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (220 > 205). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrdB7YFV7nmT"
      },
      "source": [
        "class CLPDataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    super().__init__()\n",
        "    self.token  = df.token\n",
        "    self.labels = df.target\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    if len(self.token.iloc[0]) == 2:\n",
        "      return (\n",
        "              torch.tensor(self.token.iloc[idx].input_ids), \\\n",
        "              #torch.tensor(self.token.iloc[idx].token_type_ids), \\\n",
        "              torch.tensor(self.token.iloc[idx].attention_mask)\n",
        "             ), \\\n",
        "              torch.tensor(self.labels.iloc[idx])\n",
        "    if len(self.token.iloc[idx]) == 3:\n",
        "      return (\n",
        "              torch.tensor(self.token.iloc[idx].input_ids), \\\n",
        "              torch.tensor(self.token.iloc[idx].token_type_ids), \\\n",
        "              torch.tensor(self.token.iloc[idx].attention_mask)\n",
        "             ), \\\n",
        "              torch.tensor(self.labels.iloc[idx])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96CkS0Vc8xTq"
      },
      "source": [
        "def collate_fn(batch):\n",
        "  inputs, labels = zip(*batch)\n",
        "  try:\n",
        "    ids, types, masks = zip(*inputs)\n",
        "    ids   = pad_sequence(ids, batch_first=True).to(DEVICE)\n",
        "    types = pad_sequence(types, batch_first=True).to(DEVICE)\n",
        "    masks = pad_sequence(masks, batch_first=True).to(DEVICE)\n",
        "    labels= torch.tensor(labels, dtype=torch.float).to(DEVICE)\n",
        "    return {\n",
        "        \"input_ids\"      : ids, \\\n",
        "        \"token_type_ids\" : types, \\\n",
        "        \"attention_mask\" : masks\n",
        "        }, \\\n",
        "        labels\n",
        "  except ValueError:\n",
        "    ids, masks = zip(*inputs)\n",
        "    ids   = pad_sequence(ids, batch_first=True).to(DEVICE)\n",
        "    #types = pad_sequence(types, batch_first=True).to(DEVICE)\n",
        "    masks = pad_sequence(masks, batch_first=True).to(DEVICE)\n",
        "    labels= torch.tensor(labels, dtype=torch.float).to(DEVICE)\n",
        "    return {\n",
        "        \"input_ids\"      : ids, \\\n",
        "        #\"token_type_ids\" : types, \\\n",
        "        \"attention_mask\" : masks\n",
        "        }, \\\n",
        "        labels"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1bVE8fUQImk"
      },
      "source": [
        "# trainデータを、targetの値をビニングした値を元に層化fold\n",
        "def create_folds(data, num_splits):\n",
        "    # we create a new column called kfold and fill it with -1\n",
        "    folds = pd.DataFrame( np.ones( (data.shape[0],1) )*-1, columns=['kfold'] )\n",
        "    num_bins = int(np.floor(1 + np.log2(len(data))))\n",
        "\n",
        "    bins = pd.cut(\n",
        "          data[\"target\"], bins=num_bins, labels=False\n",
        "          )\n",
        "\n",
        "    kf = model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True)\n",
        "    for f, (t_, v_) in enumerate(kf.split(X=data, y=bins)):\n",
        "        folds.iloc[v_] = int(f)\n",
        "\n",
        "    return folds"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAwOwHYgWswt"
      },
      "source": [
        "def get_dataloaders(df, folds, n_fold, BATCH_SIZE):\n",
        "  #folds = create_folds(df, num_splits=NUM_FOLDS)\n",
        "\n",
        "  train_df = df[(folds['kfold']!=n_fold)]\n",
        "  valid_df = df[(folds['kfold']==n_fold)]\n",
        "\n",
        "  train_dataset = CLPDataset(df=train_df)\n",
        "  valid_dataset = CLPDataset(df=valid_df)\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "      dataset = train_dataset,\n",
        "      batch_size = BATCH_SIZE,\n",
        "      shuffle = True,\n",
        "      collate_fn=collate_fn,\n",
        "      #num_workers = -1\n",
        "    )\n",
        "  valid_loader = DataLoader(\n",
        "      dataset = valid_dataset,\n",
        "      batch_size = BATCH_SIZE,\n",
        "      shuffle = False,\n",
        "      collate_fn=collate_fn,\n",
        "      #num_workers = -1\n",
        "    )\n",
        "  return train_loader, valid_loader"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-MCEMwL3dPt"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlpiEuiuL4pD",
        "outputId": "e8f4537c-6fc1-43ae-be13-79a2bf76bfac"
      },
      "source": [
        "folds_sample = create_folds(df, num_splits=5)\n",
        "_, sample_loader = get_dataloaders(df, folds=folds_sample, n_fold=0, BATCH_SIZE=1)\n",
        "sample_data, _ = iter(sample_loader).next()\n",
        "sample_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'),\n",
              " 'input_ids': tensor([[  101,  2006,  1996,  3174,  1011,  2117,  1997,  2337,  1010,  4947,\n",
              "           1010,  2019,  9935, 16887, 17192,  2247,  1996,  2413,  2645,  2240,\n",
              "           2008,  2005,  2471,  2048,  2086,  2018,  2218,  2067,  1996,  8749,\n",
              "           1997,  1996,  2446,  3750,  1010, 29453,  2004,  2027,  2052,  2000,\n",
              "           2663,  2037,  2126,  8736,  2046,  1996,  2540,  1997,  2605,  1012,\n",
              "           2005,  2706,  1996, 10078,  2749,  2018, 19787,  2000,  1037,  4009,\n",
              "           2013,  1996,  2167,  2712,  2000,  1996,  6192,  1997,  5288,  1010,\n",
              "           2127,  2085,  1010,  2004,  1996,  2154, 14071,  2098,  1517,  2009,\n",
              "           2001,  2471,  2416,  1051,  1005,  5119,  1517,  1996,  2398,  1997,\n",
              "           2051,  3881,  3553,  1998,  3553,  2000,  1996,  3178,  2008,  2001,\n",
              "           2000,  2928,  1996,  3098,  1997,  1996,  2087,  8618,  1998, 15615,\n",
              "           2645,  1997,  1996,  2162,  1010,  2039,  2000,  2023,  2051,  1012,\n",
              "           2009,  2001,  1996,  6574,  1997,  1996,  2645,  1997,  2310,  4103,\n",
              "           4609,  1012,  1996, 18837,  1997,  1996,  9935,  2004,  2009, 16887,\n",
              "          17192,  8597,  2093,  1012,  1999,  1996,  2392,  2835,  1010,  2894,\n",
              "           2012,  1996,  6853,  5217,  1010,  1037,  2402,  2158,  6260,  2659,\n",
              "           1012,  2002,  2001, 11721, 15185,  2098,  1999,  1996,  6375,  1997,\n",
              "           1037,  2329,  3812,  1997,  5945,  1012,  2485, 10569,  2052,  2031,\n",
              "           3936,  1996,  2755,  2008,  1996,  2402,  2158,  2001,  1037,  3360,\n",
              "           1997,  2070,  7763,  2086,  1010,  4189,  1998,  2204,  2000,  2298,\n",
              "           2588,  1012,   102]], device='cuda:0'),\n",
              " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzkR-hgi3fce"
      },
      "source": [
        "class CLPmodel(nn.Module):\n",
        "  def __init__(self, check_size=False):\n",
        "    super().__init__()\n",
        "    self.model  = get_model.from_pretrained(MODEL_PATH).to(DEVICE)\n",
        "    OUTPUT_SIZE = self.model(**sample_data)[0].shape[-1]\n",
        "    self.drop = nn.Dropout(0.5)\n",
        "    self.fc = nn.Linear(in_features=OUTPUT_SIZE, out_features=1)\n",
        "    if check_size:\n",
        "      print('base_model`s output_size :', OUTPUT_SIZE)\n",
        "      print(DEVICE)\n",
        "  \n",
        "  def forward(self,inputs):\n",
        "    out = self.model(**inputs)\n",
        "    last_hiddens = out[0]\n",
        "    out = self.drop(last_hiddens[:,0,:].squeeze(1))\n",
        "    return self.fc(out)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AqnPLl7I3Xn",
        "outputId": "69935d6c-6c0e-42a4-b041-74486ef2ce69"
      },
      "source": [
        "model = CLPmodel(check_size=True)\n",
        "del model, _\n",
        "gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "base_model`s output_size : 768\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INK-Ana_8tv7"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vbg4sw78vKg"
      },
      "source": [
        "def train_fn(model, DATA, loss_fn, optim, scheduler):\n",
        "  optim.zero_grad()\n",
        "  inputs, labels = DATA[0], DATA[1]\n",
        "  model = model.to(DEVICE)\n",
        "  pred = model(inputs)\n",
        "  loss = loss_fn(pred, labels)\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "  scheduler.step()\n",
        "  return loss.detach().cpu().numpy()\n",
        "\n",
        "def valid_fn(model, DATA, loss_fn, optim):\n",
        "  with torch.no_grad():\n",
        "    #optim.zero_grad()\n",
        "    inputs, labels = DATA[0], DATA[1]\n",
        "    model = model.to(DEVICE)\n",
        "    pred = model(inputs)\n",
        "    loss = loss_fn(pred, labels)\n",
        "    #loss.backward()\n",
        "    #optim.step()\n",
        "  return loss.detach().cpu().numpy(), pred.cpu().detach().numpy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYYtAit2Sm4G"
      },
      "source": [
        "# RMSE\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-8\n",
        "        \n",
        "    def forward(self,output,target):\n",
        "        return torch.sqrt(F.mse_loss(output,target)+self.eps)\n",
        "\n",
        "metrics = RMSELoss()\n",
        "def loss_fn(pred, labels, metrics=metrics):\n",
        "  return metrics(pred.view(-1), labels.view(-1))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mjlxetT-g_i"
      },
      "source": [
        "def train_fold(folds, n_fold, seed):\n",
        "  best_score = np.inf\n",
        "  best_model = []\n",
        "  best_pred = 0\n",
        "\n",
        "  train_loader, valid_loader = get_dataloaders(df, folds, n_fold, BATCH_SIZE)\n",
        "  model = CLPmodel().to(DEVICE)\n",
        "  optimizer = optim.Adam(params=model.parameters(), lr=5e-5)\n",
        "  lr_scheduler = CosineAnnealingLR(optimizer=optimizer, T_max=len(train_loader))\n",
        "  metrics = RMSELoss()\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    train_loss = 0\n",
        "    for DATA in tqdm(train_loader):\n",
        "      loss = train_fn(model, DATA, loss_fn, optimizer, lr_scheduler)\n",
        "      train_loss += loss\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    valid_loss = 0\n",
        "    valid_pred = np.ones(1)\n",
        "    for DATA in tqdm(valid_loader):\n",
        "      loss, pred = valid_fn(model, DATA, loss_fn, optimizer)\n",
        "      valid_pred = np.concatenate([valid_pred, pred.reshape(-1,)], axis=0)\n",
        "      valid_loss += loss\n",
        "    valid_loss /= len(valid_loader)\n",
        "\n",
        "    print(f\"seed : {seed}, fold : {n_fold}, epoch : {epoch}, train_loss : {train_loss}\")\n",
        "    print(f\"seed : {seed}, fold : {n_fold}, epoch : {epoch}, valid_loss : {valid_loss}\")\n",
        "    print('='*30)\n",
        "\n",
        "    if valid_loss < best_score:\n",
        "      best_socre = valid_loss\n",
        "      del best_model, best_pred\n",
        "      gc.collect()\n",
        "      best_model = copy.deepcopy(model)\n",
        "      best_pred  = valid_pred[1:]   \n",
        "  #best_model.save()\n",
        "  return best_pred"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPO3uMDkF-0Z"
      },
      "source": [
        "def train_seed(seed):\n",
        "  seed_everything(seed)\n",
        "  folds = create_folds(df, num_splits=NUM_FOLDS)\n",
        "  oof   = np.zeros(df['target'].shape)\n",
        "\n",
        "  for n_fold in range(NUM_FOLDS):\n",
        "    best_pred = train_fold(folds, n_fold, seed)\n",
        "    oof[(folds['kfold']==n_fold)] = best_pred\n",
        "    print('-='*20)\n",
        "\n",
        "  print('%'*50)\n",
        "  oof_score = loss_fn(pred   = torch.tensor(oof).to(DEVICE),\n",
        "                      labels = torch.tensor(df['target'].values).to(DEVICE) )\n",
        "  print(f'oof_score_{seed} :', oof_score.cpu().detach().numpy())\n",
        "  return oof_score.cpu().detach().numpy()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3itPcgeDKqQe"
      },
      "source": [
        "EPOCHS = 1\n",
        "DEVICE = 'cuda:0'\n",
        "SEEDs = [0]\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "NUM_FOLDS = 3\n",
        "\n",
        "MAX_WORDS = df[\"excerpt\"].apply(lambda x: len(x.split())).max()\n",
        "\n",
        "oof_scores  = []\n",
        "for seed in SEEDs:\n",
        "  print(f'--------------- SEED {seed} is set ---------------')\n",
        "  oof_score_for_seed = train_seed(seed)\n",
        "  oof_scores.append(oof_score_for_seed)\n",
        "\n",
        "print('&%&%'*30)\n",
        "print(f\"all_oof_score_avg : {oof_scores}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}